[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Qelabs_jp_typhoon_map_v02",
    "section": "",
    "text": "Tidy up Japanâ€™s typhoon data from 1951 to 2023.\nCreate interactive map."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "tidyup.html",
    "href": "tidyup.html",
    "title": "Tidy-up Japan Typhoon Data",
    "section": "",
    "text": "Tidy up Japan Typhoon data from 1951 to 2023.\n\n\nimport modules\n\n\nCode\nimport os\nfrom typing import List\n\nimport polars as pl\npl.Config.set_tbl_rows(7)   # limit num of lines for table preview\nprint('polars version', pl.__version__)\n\n\npolars version 0.20.9\n\n\n\n\ncreate df schema as a dict {\"col_name\", pl.DataType}\n\n\nCode\ndf_schema = {\n    'h_a_indicator'               : pl.String,\n    'h_b_int_num_id'              : pl.String,\n    'h_c_num_data'                : pl.String,\n    'h_d_tropical_cyclone_num_id' : pl.String,\n    'h_e_int_num_id'              : pl.String,\n    'h_f_flag_last_data_line'     : pl.String,\n    'h_g_diff_hour'               : pl.String,\n    'h_h_storm_name'              : pl.String,\n    'h_i_date_last_rev'           : pl.String,\n    'd_a_date_time'               : pl.String,\n    'd_b_indicator'               : pl.String,\n    'd_c_grade'                   : pl.String,\n    'd_d_latitude'                : pl.String,\n    'd_e_longitude'               : pl.String,\n    'd_f_central_pressure_dPa'    : pl.String,\n    'd_g_max_wind_speed_kt'       : pl.String,\n    'd_h_dir_longest_r_50kt_wind' : pl.String,\n    'd_i_longest_r_50kt_wind_nm'  : pl.String,\n    'd_j_shortest_r_50kt_wind_nm' : pl.String,\n    'd_k_dir_longest_r_30kt_wind' : pl.String,\n    'd_l_longest_r_30kt_wind_nm'  : pl.String,\n    'd_m_shortest_r_30kt_wind_nm' : pl.String,\n    'd_p_landfall_or_passage'     : pl.String,\n}\n\n# print('type of df_schema:', type(df_schema))\nprint(df_schema)\n\n\n{'h_a_indicator': String, 'h_b_int_num_id': String, 'h_c_num_data': String, 'h_d_tropical_cyclone_num_id': String, 'h_e_int_num_id': String, 'h_f_flag_last_data_line': String, 'h_g_diff_hour': String, 'h_h_storm_name': String, 'h_i_date_last_rev': String, 'd_a_date_time': String, 'd_b_indicator': String, 'd_c_grade': String, 'd_d_latitude': String, 'd_e_longitude': String, 'd_f_central_pressure_dPa': String, 'd_g_max_wind_speed_kt': String, 'd_h_dir_longest_r_50kt_wind': String, 'd_i_longest_r_50kt_wind_nm': String, 'd_j_shortest_r_50kt_wind_nm': String, 'd_k_dir_longest_r_30kt_wind': String, 'd_l_longest_r_30kt_wind_nm': String, 'd_m_shortest_r_30kt_wind_nm': String, 'd_p_landfall_or_passage': String}\n\n\n\n\ncreate an empty dataframe\n\n\nCode\nlist_col_names = list(df_schema.keys())\n\ndict_empty_data = {\n    'h_a_indicator'               : [],\n    'h_b_int_num_id'              : [],\n    'h_c_num_data'                : [],\n    'h_d_tropical_cyclone_num_id' : [],\n    'h_e_int_num_id'              : [],\n    'h_f_flag_last_data_line'     : [],\n    'h_g_diff_hour'               : [],\n    'h_h_storm_name'              : [],\n    'h_i_date_last_rev'           : [],\n    'd_a_date_time'               : [],\n    'd_b_indicator'               : [],\n    'd_c_grade'                   : [],\n    'd_d_latitude'                : [],\n    'd_e_longitude'               : [],\n    'd_f_central_pressure_dPa'    : [],\n    'd_g_max_wind_speed_kt'       : [],\n    'd_h_dir_longest_r_50kt_wind' : [],\n    'd_i_longest_r_50kt_wind_nm'  : [],\n    'd_j_shortest_r_50kt_wind_nm' : [],\n    'd_k_dir_longest_r_30kt_wind' : [],\n    'd_l_longest_r_30kt_wind_nm'  : [],\n    'd_m_shortest_r_30kt_wind_nm' : [],\n    'd_p_landfall_or_passage'     : [],\n}\n\ndf= pl.DataFrame(dict_empty_data, df_schema)\ndf\n\n\n\n\nshape: (0, 23)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\n\n\n\n\n\n\nread the data file, extract header lines and data lines\n\n\nCode\n%time\n\n# row data file path\n# data_file_path = './data/RSMC_Tokyo_Typhoon_1951-2023.txt'\n# data_file_path = './data/RSMC_Tokyo_Typhoon_2013-2023.txt'\n# data_file_path = './data/RSMC_Tokyo_Typhoon_2019-2023.txt'\nraw_data_file_path = './data/original/RSMC_Tokyo_Typhoon_2021-2023.txt'\n# raw_data_file_path = './data/original/RSMC_Tokyo_Typhoon_2023.txt'\n\n# extracted header and data file paths\nextracted_header_f_path = './data/processed/header.txt'\nextracted_data_f_path = './data/processed/data.txt'\n\n# remove header and data files, if they exists\nif os.path.exists(extracted_header_f_path):\n    os.remove(extracted_header_f_path)\n\nif os.path.exists(extracted_data_f_path):\n    os.remove(extracted_data_f_path)\n\n# open header and data file to write\nf_header = open(extracted_header_f_path, 'w')\nf_data = open(extracted_data_f_path, 'w')\n\n# extract header lines and data lines into different files\nwith open(raw_data_file_path) as f:\n    # read all the lines\n    lines = f.readlines()\n\n    # read each line\n    for line in lines:\n        # check if a line is a header/data by the length of its 1st split\n        if len(line.split()[0]) == 5:\n            # add header to f_header\n            f_header.write(line)\n\n        elif len(line.split()[0]) == 8:\n            # add data line to f_data\n            f_data.write(line)\n\nf_header.close()\nf_data.close()\n\n\nCPU times: total: 0 ns\nWall time: 0 ns\n\n\n\n\nfunc to vstack each data record to df\n\n\nCode\ndef vstack_df(\n    _col_names: List[str], \n    _record_items: List[str], \n    _df: pl.DataFrame,\n) -&gt; pl.DataFrame:\n\n    # create a dict from list of col names and a list of data items\n    dict_record = dict(\n        zip(\n            _col_names, \n            _record_items,\n        )\n    )\n\n    df_to_stack = pl.DataFrame(dict_record)\n\n    _df = _df.vstack(df_to_stack)\n\n    return _df\n\n\n\n\nread header and data files to create dataframe\n\n\nCode\nwith open(extracted_header_f_path, 'r') as f_h:\n    h_lines = f_h.readlines()\n\n    header_cnt = 0\n\n    f_data_line_num_start = 0\n    f_data_line_num_end = -1\n\n    for h_line in h_lines:\n        # create an empty list to store header and data for each record\n        headedr_items = []\n\n        # get info from header col by col\n        h_a = h_line[0:5]\n        h_b = h_line[6:10]\n        h_c = h_line[12:15]\n        h_d = h_line[16:20]\n        h_e = h_line[21:25]\n        h_f = h_line[26]\n        h_g = h_line[28]\n        h_h = h_line[30:50].strip()\n        h_i = h_line[64:72]\n\n        # calc obsolute start and end line num in f_data to read\n        # ...new start_line_num = previous end_line_num +1\n        f_data_line_num_start = f_data_line_num_end + 1 \n        # ...new end_line_num = new start_line_num + num_data_lines of the current data chunk\n        f_data_line_num_end = f_data_line_num_start + int(h_c) - 1 \n\n        headedr_items.extend([ \n            h_a, \n            h_b,\n            h_c,\n            h_d,\n            h_e,\n            h_f,\n            h_g,\n            h_h,\n            h_i\n        ])\n\n        print('header:', header_cnt, '\\t', headedr_items)\n\n        # read data file by the start and end line numbers\n        f_data = './data/processed/data.txt'\n\n        with open(f_data, 'r') as f_data:\n            for idx, d_line in enumerate(f_data):\n                record_items = []\n\n                if f_data_line_num_start &lt;= idx &lt;= f_data_line_num_end:\n                    data_items = []\n\n                    d_a = d_line[0:8].strip()\n                    d_b = d_line[9:12].strip()\n                    d_c = d_line[13:14].strip()\n                    d_d = d_line[15:18].strip()\n                    d_e = d_line[19:23].strip()\n                    d_f = d_line[24:28].strip()\n                    d_g = d_line[33:36].strip()\n                    d_h = d_line[41].strip()\n                    d_i = d_line[42:46].strip()\n                    d_j = d_line[47:51].strip()\n                    d_k = d_line[52].strip()\n                    d_l = d_line[53:57].strip()\n                    d_m = d_line[58:62].strip()\n                    d_p = d_line[71].strip()\n\n                    data_items.extend([\n                        d_a,\n                        d_b,\n                        d_c,\n                        d_d,\n                        d_e,\n                        d_f,\n                        d_g,\n                        d_h,\n                        d_i,\n                        d_j,\n                        d_k,\n                        d_l,\n                        d_m,\n                        d_p\n                    ])\n\n                    # join the lists of header and data items\n                    record_items = headedr_items + data_items\n\n                    # stack the df created from the current record to df\n                    # option 1:\n                    # dict_record = dict(zip(list_col_names, record_items))\n                    # df_to_stack = pl.DataFrame(dict_record)\n                    # df = df.vstack(df_to_stack)\n                    # option 2:\n                    df = vstack_df(list_col_names, record_items, df)\n\n                    # # cherry-print a data line for verification\n                    # if idx == 337:\n                    #     print(record_items)\n\n        header_cnt += 1\ndf\n\n\nheader: 0    ['66666', '2101', '028', '0001', '2101', '0', '6', 'DUJUAN', '20210520']\nheader: 1    ['66666', '2102', '073', '0002', '2102', '1', '0', 'SURIGAE', '20210715']\nheader: 2    ['66666', '2103', '033', '0004', '2103', '0', '6', 'CHOI-WAN', '20210826']\nheader: 3    ['66666', '2104', '011', '0005', '2104', '0', '6', 'KOGUMA', '20210826']\nheader: 4    ['66666', '2105', '036', '0006', '2105', '0', '6', 'CHAMPI', '20210909']\nheader: 5    ['66666', '2106', '081', '0009', '2106', '0', '6', 'IN-FA', '20211028']\nheader: 6    ['66666', '2107', '033', '0010', '2107', '0', '6', 'CEMPAKA', '20211101']\nheader: 7    ['66666', '2108', '037', '0011', '2108', '0', '6', 'NEPARTAK', '20211102']\nheader: 8    ['66666', '2109', '056', '0014', '2109', '0', '6', 'LUPIT', '20211104']\nheader: 9    ['66666', '2110', '032', '0016', '2110', '0', '6', 'MIRINAE', '20211110']\nheader: 10   ['66666', '2111', '021', '0015', '2111', '0', '6', 'NIDA', '20211110']\nheader: 11   ['66666', '2112', '055', '0018', '2112', '0', '6', 'OMAIS', '20211201']\nheader: 12   ['66666', '2113', '034', '0020', '2113', '0', '6', 'CONSON', '20211214']\nheader: 13   ['66666', '2114', '070', '0021', '2114', '0', '6', 'CHANTHU', '20211218']\nheader: 14   ['66666', '2115', '017', '0022', '2115', '1', '0', 'DIANMU', '20211220']\nheader: 15   ['66666', '2116', '057', '0023', '2116', '1', '0', 'MINDULLE', '20211225']\nheader: 16   ['66666', '2117', '024', '0024', '2117', '0', '6', 'LIONROCK', '20220106']\nheader: 17   ['66666', '2118', '031', '0025', '2118', '0', '6', 'KOMPASU', '20220106']\nheader: 18   ['66666', '2119', '042', '0026', '2119', '1', '0', 'NAMTHEUN', '20220107']\nheader: 19   ['66666', '2120', '039', '0027', '2120', '1', '0', 'MALOU', '20220119']\nheader: 20   ['66666', '2121', '023', '0028', '2121', '0', '6', 'NYATOH', '20220204']\nheader: 21   ['66666', '2122', '039', '0029', '2122', '0', '6', 'RAI', '20220204']\nheader: 22   ['66666', '2201', '052', '0001', '2201', '1', '0', 'MALAKAS', '20220715']\nheader: 23   ['66666', '2202', '014', '0002', '2202', '0', '6', 'MEGI', '20220716']\nheader: 24   ['66666', '2203', '037', '0003', '2203', '0', '6', 'CHABA', '20221005']\nheader: 25   ['66666', '2204', '043', '0004', '2204', '0', '6', 'AERE', '20221006']\nheader: 26   ['66666', '2205', '024', '0006', '2205', '0', '6', 'SONGDA', '20221007']\nheader: 27   ['66666', '2206', '014', '0007', '2206', '0', '6', 'TRASES', '20221101']\nheader: 28   ['66666', '2207', '014', '0008', '2207', '0', '6', 'MULAN', '20221101']\nheader: 29   ['66666', '2208', '035', '0009', '2208', '1', '0', 'MEARI', '20221116']\nheader: 30   ['66666', '2209', '021', '0010', '2209', '0', '6', 'MA-ON', '20221116']\nheader: 31   ['66666', '2210', '024', '0011', '2210', '1', '0', 'TOKAGE', '20221120']\nheader: 32   ['66666', '2211', '069', '0013', '2211', '1', '0', 'HINNAMNOR', '20221124']\nheader: 33   ['66666', '2212', '063', '0016', '2212', '0', '6', 'MUIFA', '20221124']\nheader: 34   ['66666', '2213', '026', '0017', '2213', '1', '0', 'MERBOK', '20221125']\nheader: 35   ['66666', '2214', '047', '0018', '2214', '0', '6', 'NANMADOL', '20221219']\nheader: 36   ['66666', '2215', '028', '0019', '2215', '0', '6', 'TALAS', '20221223']\nheader: 37   ['66666', '2216', '033', '0020', '2216', '0', '6', 'NORU', '20221226']\nheader: 38   ['66666', '2217', '028', '0021', '2217', '1', '0', 'KULAP', '20230104']\nheader: 39   ['66666', '2218', '032', '0022', '2218', '0', '6', 'ROKE', '20230104']\nheader: 40   ['66666', '2219', '008', '0023', '2219', '0', '6', 'SONCA', '20230104']\nheader: 41   ['66666', '2220', '024', '0025', '2220', '0', '6', 'NESAT', '20230104']\nheader: 42   ['66666', '2221', '015', '0026', '2221', '1', '0', 'HAITANG', '20230112']\nheader: 43   ['66666', '2222', '033', '0028', '2222', '0', '6', 'NALGAE', '20230112']\nheader: 44   ['66666', '2223', '024', '0029', '2223', '0', '6', 'BANYAN', '20230117']\nheader: 45   ['66666', '2224', '014', '0030', '2224', '0', '6', 'YAMANEKO', '20230119']\nheader: 46   ['66666', '2225', '011', '0031', '2225', '0', '6', 'PAKHAR', '20230123']\nheader: 47   ['66666', '2301', '014', '0003', '2301', '0', '6', 'SANVU', '20230704']\nheader: 48   ['66666', '2302', '067', '0004', '2302', '0', '6', 'MAWAR', '20230830']\nheader: 49   ['66666', '2303', '044', '0005', '2303', '1', '0', 'GUCHOL', '20230906']\nheader: 50   ['66666', '2304', '023', '0006', '2304', '0', '6', 'TALIM', '20231025']\nheader: 51   ['66666', '2305', '042', '0007', '2305', '0', '6', 'DOKSURI', '20231025']\nheader: 52   ['66666', '2306', '106', '0008', '2306', '0', '6', 'KHANUN', '20231027']\nheader: 53   ['66666', '2307', '061', '0009', '2307', '0', '6', 'LAN', '20231114']\nheader: 54   ['66666', '2308', '042', '0010', '2308', '1', '0', 'DORA', '20231115']\nheader: 55   ['66666', '2309', '051', '0011', '2309', '0', '6', 'SAOLA', '20231127']\nheader: 56   ['66666', '2310', '028', '0012', '2310', '1', '0', 'DAMREY', '20231127']\nheader: 57   ['66666', '2311', '040', '0013', '2311', '0', '6', 'HAIKUI', '20231127']\nheader: 58   ['66666', '2312', '032', '0014', '2312', '0', '6', 'KIROGI', '20231128']\nheader: 59   ['66666', '2313', '019', '0015', '2313', '0', '6', 'YUN-YEUNG', '20231129']\nheader: 60   ['66666', '2314', '046', '0016', '2314', '0', '6', 'KOINU', '20240110']\nheader: 61   ['66666', '2315', '039', '0017', '2315', '1', '0', 'BOLAVEN', '20240110']\nheader: 62   ['66666', '2316', '013', '0018', '2316', '0', '6', 'SANBA', '20240111']\n\n\n\n\nshape: (2_272, 23)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"66666\"\n\"2101\"\n\"028\"\n\"0001\"\n\"2101\"\n\"0\"\n\"6\"\n\"DUJUAN\"\n\"20210520\"\n\"21021606\"\n\"002\"\n\"2\"\n\"069\"\n\"1369\"\n\"1004\"\n\"000\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\n\n\"66666\"\n\"2101\"\n\"028\"\n\"0001\"\n\"2101\"\n\"0\"\n\"6\"\n\"DUJUAN\"\n\"20210520\"\n\"21021612\"\n\"002\"\n\"2\"\n\"069\"\n\"1362\"\n\"1006\"\n\"000\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\n\n\"66666\"\n\"2101\"\n\"028\"\n\"0001\"\n\"2101\"\n\"0\"\n\"6\"\n\"DUJUAN\"\n\"20210520\"\n\"21021618\"\n\"002\"\n\"2\"\n\"068\"\n\"1351\"\n\"1004\"\n\"000\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\"66666\"\n\"2316\"\n\"013\"\n\"0018\"\n\"2316\"\n\"0\"\n\"6\"\n\"SANBA\"\n\"20240111\"\n\"23101918\"\n\"002\"\n\"3\"\n\"214\"\n\"1095\"\n\"1002\"\n\"035\"\n\"0\"\n\"0000\"\n\"0000\"\n\"9\"\n\"0150\"\n\"0150\"\n\"\"\n\n\n\"66666\"\n\"2316\"\n\"013\"\n\"0018\"\n\"2316\"\n\"0\"\n\"6\"\n\"SANBA\"\n\"20240111\"\n\"23102000\"\n\"002\"\n\"2\"\n\"214\"\n\"1098\"\n\"1008\"\n\"000\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\n\n\"66666\"\n\"2316\"\n\"013\"\n\"0018\"\n\"2316\"\n\"0\"\n\"6\"\n\"SANBA\"\n\"20240111\"\n\"23102006\"\n\"002\"\n\"2\"\n\"209\"\n\"1097\"\n\"1008\"\n\"000\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\"\"\n\n\n\n\n\n\n\n\n\nreplace empty string with â€˜nullâ€™\n\n\nCode\ndf = df.select(\n    # pl.when(pl.col(pl.Utf8).str.lengths()==0) # lengths() deprecated\n    #   .then(None)\n    #   .otherwise(pl.col(pl.Utf8))             # pl.Utf8 replaced by pl.String\n    #   .keep_name()                            # .keep_name() deprecated\n\n    pl.when(pl.col(pl.Utf8).str.len_bytes()==0)\n      .then(None)\n      .otherwise(pl.col(pl.String))\n      .name.keep()\n)\ndf\n\n\n\n\nshape: (2_272, 23)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"66666\"\n\"2101\"\n\"028\"\n\"0001\"\n\"2101\"\n\"0\"\n\"6\"\n\"DUJUAN\"\n\"20210520\"\n\"21021606\"\n\"002\"\n\"2\"\n\"069\"\n\"1369\"\n\"1004\"\n\"000\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"66666\"\n\"2101\"\n\"028\"\n\"0001\"\n\"2101\"\n\"0\"\n\"6\"\n\"DUJUAN\"\n\"20210520\"\n\"21021612\"\n\"002\"\n\"2\"\n\"069\"\n\"1362\"\n\"1006\"\n\"000\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"66666\"\n\"2101\"\n\"028\"\n\"0001\"\n\"2101\"\n\"0\"\n\"6\"\n\"DUJUAN\"\n\"20210520\"\n\"21021618\"\n\"002\"\n\"2\"\n\"068\"\n\"1351\"\n\"1004\"\n\"000\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\"66666\"\n\"2316\"\n\"013\"\n\"0018\"\n\"2316\"\n\"0\"\n\"6\"\n\"SANBA\"\n\"20240111\"\n\"23101918\"\n\"002\"\n\"3\"\n\"214\"\n\"1095\"\n\"1002\"\n\"035\"\n\"0\"\n\"0000\"\n\"0000\"\n\"9\"\n\"0150\"\n\"0150\"\nnull\n\n\n\"66666\"\n\"2316\"\n\"013\"\n\"0018\"\n\"2316\"\n\"0\"\n\"6\"\n\"SANBA\"\n\"20240111\"\n\"23102000\"\n\"002\"\n\"2\"\n\"214\"\n\"1098\"\n\"1008\"\n\"000\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"66666\"\n\"2316\"\n\"013\"\n\"0018\"\n\"2316\"\n\"0\"\n\"6\"\n\"SANBA\"\n\"20240111\"\n\"23102006\"\n\"002\"\n\"2\"\n\"209\"\n\"1097\"\n\"1008\"\n\"000\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\n\ncast data type for columns\n\n\nCode\ndf = df.with_columns(\n    pl.col('h_a_indicator').cast(pl.Int32),\n    pl.col('h_b_int_num_id').cast(pl.Int16),\n    pl.col('h_c_num_data').cast(pl.Int16),\n    pl.col('h_d_tropical_cyclone_num_id').cast(pl.Int8),\n    pl.col('h_e_int_num_id').cast(pl.Int16),\n    pl.col('h_f_flag_last_data_line').cast(pl.Int8),\n    pl.col('h_g_diff_hour').cast(pl.Int8),\n    pl.col('d_b_indicator').cast(pl.Int8),\n    pl.col('d_c_grade').cast(pl.Int8),\n    pl.col('d_d_latitude').cast(pl.Float64),\n    pl.col('d_e_longitude').cast(pl.Float64),\n    pl.col('d_f_central_pressure_dPa').cast(pl.Int16),\n    pl.col('d_g_max_wind_speed_kt').cast(pl.Int16),\n    pl.col('d_h_dir_longest_r_50kt_wind').cast(pl.Int16),\n    pl.col('d_i_longest_r_50kt_wind_nm').cast(pl.Int16),\n    pl.col('d_j_shortest_r_50kt_wind_nm').cast(pl.Int16),\n    pl.col('d_k_dir_longest_r_30kt_wind').cast(pl.Int16),\n    pl.col('d_l_longest_r_30kt_wind_nm').cast(pl.Int16),\n    pl.col('d_m_shortest_r_30kt_wind_nm').cast(pl.Int16),\n)\ndf\n\n\n\n\nshape: (2_272, 23)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\n\n\ni32\ni16\ni16\ni8\ni16\ni8\ni8\nstr\nstr\nstr\ni8\ni8\nf64\nf64\ni16\ni16\ni16\ni16\ni16\ni16\ni16\ni16\nstr\n\n\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"21021606\"\n2\n2\n69.0\n1369.0\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"21021612\"\n2\n2\n69.0\n1362.0\n1006\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"21021618\"\n2\n2\n68.0\n1351.0\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"23101918\"\n2\n3\n214.0\n1095.0\n1002\n35\n0\n0\n0\n9\n150\n150\nnull\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"23102000\"\n2\n2\n214.0\n1098.0\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"23102006\"\n2\n2\n209.0\n1097.0\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\n\nadd 4 0 @ end of each item in d_a_date_time column\n\n\nCode\ndf =  df.with_columns(\n    pl.col('d_a_date_time').str.pad_end(12, \"0\")\n)\ndf\n\n\n\n\nshape: (2_272, 23)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\n\n\ni32\ni16\ni16\ni8\ni16\ni8\ni8\nstr\nstr\nstr\ni8\ni8\nf64\nf64\ni16\ni16\ni16\ni16\ni16\ni16\ni16\ni16\nstr\n\n\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216060000\"\n2\n2\n69.0\n1369.0\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216120000\"\n2\n2\n69.0\n1362.0\n1006\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216180000\"\n2\n2\n68.0\n1351.0\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231019180000\"\n2\n3\n214.0\n1095.0\n1002\n35\n0\n0\n0\n9\n150\n150\nnull\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020000000\"\n2\n2\n214.0\n1098.0\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020060000\"\n2\n2\n209.0\n1097.0\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\n\nadd datetime column\n\n\nCode\ndf = df.with_columns(\n    # pl.col('h_i_date_last_rev')\n    #   .str.strptime(pl.Date, format=\"%Y%m%d\")\n    #   .alias('date_last_rev'),\n    pl.col('d_a_date_time')\n      .str.strptime(pl.Datetime, format=\"%y%m%d%H%M%S\")\n      .alias('date_time'),\n)\ndf\n\n\n\n\nshape: (2_272, 24)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\ndate_time\n\n\ni32\ni16\ni16\ni8\ni16\ni8\ni8\nstr\nstr\nstr\ni8\ni8\nf64\nf64\ni16\ni16\ni16\ni16\ni16\ni16\ni16\ni16\nstr\ndatetime[Î¼s]\n\n\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216060000\"\n2\n2\n69.0\n1369.0\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 06:00:00\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216120000\"\n2\n2\n69.0\n1362.0\n1006\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 12:00:00\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216180000\"\n2\n2\n68.0\n1351.0\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 18:00:00\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231019180000\"\n2\n3\n214.0\n1095.0\n1002\n35\n0\n0\n0\n9\n150\n150\nnull\n2023-10-19 18:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020000000\"\n2\n2\n214.0\n1098.0\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 00:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020060000\"\n2\n2\n209.0\n1097.0\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 06:00:00\n\n\n\n\n\n\n\n\n\nadjust lat and lon value\n\n\nCode\ndf = df.with_columns(\n    pl.col(\"d_d_latitude\").mul(0.1), \n    pl.col(\"d_e_longitude\").mul(0.1)\n)\ndf\n\n\n\n\nshape: (2_272, 24)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\ndate_time\n\n\ni32\ni16\ni16\ni8\ni16\ni8\ni8\nstr\nstr\nstr\ni8\ni8\nf64\nf64\ni16\ni16\ni16\ni16\ni16\ni16\ni16\ni16\nstr\ndatetime[Î¼s]\n\n\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216060000\"\n2\n2\n6.9\n136.9\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 06:00:00\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216120000\"\n2\n2\n6.9\n136.2\n1006\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 12:00:00\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216180000\"\n2\n2\n6.8\n135.1\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 18:00:00\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231019180000\"\n2\n3\n21.4\n109.5\n1002\n35\n0\n0\n0\n9\n150\n150\nnull\n2023-10-19 18:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020000000\"\n2\n2\n21.4\n109.8\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 00:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020060000\"\n2\n2\n20.9\n109.7\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 06:00:00\n\n\n\n\n\n\n\n\n\ncheck result\n\n\nCode\n# df.describe()\n\n\n\n\nwrite df as parquet\n\n\nCode\ndf_parquet_f_path = \"./data/processed/df.parquet\"\n\n# remove parquet file, if it exists\nif os.path.exists(df_parquet_f_path):\n    os.remove(df_parquet_f_path)\n\ndf.write_parquet(df_parquet_f_path)\nprint('df written as parquet file')\n\n\ndf written as parquet file\n\n\n\n\ncreate map\nimport plotly.express as px\n\ndf = pl.read_parquet(df_parquet_f_path)\nprint('read df as parquet')\n\nfig = px.line_mapbox(\n    df,\n    # lat=df[\"d_d_latitude\"],\n    # lon=df[\"d_e_longitude\"],\n    # color=df[\"h_b_int_num_id\"],\n    lat=\"d_d_latitude\",\n    lon=\"d_e_longitude\",\n    color=\"h_b_int_num_id\",\n    zoom=3,\n    height=1000,\n    # animation_frame=\"h_b_int_num_id\"\n)\n\nfig.update_layout(\n    # mapbox_style=\"open-street-map\",\n    mapbox_style=\"carto-darkmatter\",\n    # mapbox_zoom=4,\n    mapbox_center_lat=36,\n    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n)\n\nfig.show()",
    "crumbs": [
      "Home",
      "Production",
      "Tidy-up Japan Typhoon Data"
    ]
  },
  {
    "objectID": "plot.html",
    "href": "plot.html",
    "title": "create map",
    "section": "",
    "text": "Create map for Japan Typhoon data from 1951 to 2023.\n\n\nimport modules\n\n\nCode\nimport polars as pl\npl.Config.set_tbl_rows(7)   # limit num of lines for table preview\nimport plotly.express as px\n\nprint('polars:', pl.__version__)\n\n\npolars: 0.20.9\n\n\n\n\nread df parquet\n\n\nCode\n%time\n\ndf_parquet_f_path = \"./data/processed/df.parquet\"\ndf = pl.read_parquet(df_parquet_f_path)\nprint('read df as parquet')\ndf\n\n\nCPU times: total: 0 ns\nWall time: 0 ns\nread df as parquet\n\n\n\n\nshape: (2_272, 24)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\ndate_time\n\n\ni32\ni16\ni16\ni8\ni16\ni8\ni8\nstr\nstr\nstr\ni8\ni8\nf64\nf64\ni16\ni16\ni16\ni16\ni16\ni16\ni16\ni16\nstr\ndatetime[Î¼s]\n\n\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216060000\"\n2\n2\n6.9\n136.9\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 06:00:00\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216120000\"\n2\n2\n6.9\n136.2\n1006\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 12:00:00\n\n\n66666\n2101\n28\n1\n2101\n0\n6\n\"DUJUAN\"\n\"20210520\"\n\"210216180000\"\n2\n2\n6.8\n135.1\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2021-02-16 18:00:00\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231019180000\"\n2\n3\n21.4\n109.5\n1002\n35\n0\n0\n0\n9\n150\n150\nnull\n2023-10-19 18:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020000000\"\n2\n2\n21.4\n109.8\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 00:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020060000\"\n2\n2\n20.9\n109.7\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 06:00:00\n\n\n\n\n\n\n\n\n\nfilter data by year range\n\n\nCode\nyear_range = [2022, 2023]\n\ndf_filtered = df.filter(\n    pl.col('date_time')\n      .dt.year()\n      .is_between(year_range[0], year_range[1])\n)\nprint('df filtered by year range:')\ndf_filtered\n\n\ndf filtered by year range:\n\n\n\n\nshape: (1_400, 24)\n\n\n\nh_a_indicator\nh_b_int_num_id\nh_c_num_data\nh_d_tropical_cyclone_num_id\nh_e_int_num_id\nh_f_flag_last_data_line\nh_g_diff_hour\nh_h_storm_name\nh_i_date_last_rev\nd_a_date_time\nd_b_indicator\nd_c_grade\nd_d_latitude\nd_e_longitude\nd_f_central_pressure_dPa\nd_g_max_wind_speed_kt\nd_h_dir_longest_r_50kt_wind\nd_i_longest_r_50kt_wind_nm\nd_j_shortest_r_50kt_wind_nm\nd_k_dir_longest_r_30kt_wind\nd_l_longest_r_30kt_wind_nm\nd_m_shortest_r_30kt_wind_nm\nd_p_landfall_or_passage\ndate_time\n\n\ni32\ni16\ni16\ni8\ni16\ni8\ni8\nstr\nstr\nstr\ni8\ni8\nf64\nf64\ni16\ni16\ni16\ni16\ni16\ni16\ni16\ni16\nstr\ndatetime[Î¼s]\n\n\n\n\n66666\n2201\n52\n1\n2201\n1\n0\n\"MALAKAS\"\n\"20220715\"\n\"220406060000\"\n2\n2\n3.4\n150.2\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2022-04-06 06:00:00\n\n\n66666\n2201\n52\n1\n2201\n1\n0\n\"MALAKAS\"\n\"20220715\"\n\"220406120000\"\n2\n2\n3.5\n149.6\n1006\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2022-04-06 12:00:00\n\n\n66666\n2201\n52\n1\n2201\n1\n0\n\"MALAKAS\"\n\"20220715\"\n\"220406180000\"\n2\n2\n3.5\n149.1\n1004\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2022-04-06 18:00:00\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231019180000\"\n2\n3\n21.4\n109.5\n1002\n35\n0\n0\n0\n9\n150\n150\nnull\n2023-10-19 18:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020000000\"\n2\n2\n21.4\n109.8\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 00:00:00\n\n\n66666\n2316\n13\n18\n2316\n0\n6\n\"SANBA\"\n\"20240111\"\n\"231020060000\"\n2\n2\n20.9\n109.7\n1008\n0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n2023-10-20 06:00:00\n\n\n\n\n\n\n\n\n\ncreate map\n\n\nCode\nfig = px.line_mapbox(\n    df_filtered,\n    # lat=df_filtered[\"d_d_latitude\"],\n    # lon=df_filtered[\"d_e_longitude\"],\n    lat=\"d_d_latitude\",\n    lon=\"d_e_longitude\",\n    color=\"h_b_int_num_id\",\n    zoom=3,\n    height=1000,\n    # animation_frame=\"h_b_int_num_id\"\n)\n\nfig.update_layout(\n    # mapbox_style=\"open-street-map\",\n    mapbox_style=\"carto-darkmatter\",\n    # mapbox_zoom=4,\n    mapbox_center_lat=36,\n    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n)\n\nfig.show()",
    "crumbs": [
      "Home",
      "Production",
      "create map"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "test code",
    "section": "",
    "text": "import modules\n\n\nCode\nimport polars as pl\nprint('polars version', pl.__version__)\n\n\npolars version 0.20.9\n\n\n\n\ntest, create an empty dataframe with a list of column names\n\n\nCode\nkeys = ['a', 'b', 'c']\ncol_names = dict.fromkeys(keys)\ndf = pl.DataFrame(col_names)\ndf\n\n\n\n\nshape: (1, 3)\n\n\n\na\nb\nc\n\n\nnull\nnull\nnull\n\n\n\n\nnull\nnull\nnull\n\n\n\n\n\n\n\n\n\ncreate a pl df from schema & data\n\n\nCode\ndf_schema = {\n    'a': pl.Int64,\n    'b': pl.String,\n    'c': pl.Float64,\n}\n\n# data = {\n#     'a': 12345,\n#     'b': 'abc',\n#     'c': 123.45\n# }\n\ndata = {\n    'a': [],\n    'b': [],\n    'c': [],\n}\n\ndf2 = pl.DataFrame(data, schema=df_schema)\n\ndf2\n\n\n\n\nshape: (0, 3)\n\n\n\na\nb\nc\n\n\ni64\nstr\nf64\n\n\n\n\n\n\n\n\n\n\n\nuse df.vstack to stack 2 df\n\n\nCode\ndict_df3_data = {\n    'a': [6299, 54321],\n    'b': ['agb', 'bca'],\n    'c': [123.45, 43.213]\n}\ndf3 = pl.DataFrame(dict_df3_data)\n\ndf2 = df2.vstack(df3)\ndf2\n\n\n\n\nshape: (2, 3)\n\n\n\na\nb\nc\n\n\ni64\nstr\nf64\n\n\n\n\n6299\n\"agb\"\n123.45\n\n\n54321\n\"bca\"\n43.213\n\n\n\n\n\n\n\n\n\nconvert str to yyyymmddhh\n\n\nCode\ndf_date = pl.DataFrame({\n    'date_h_str': ['1987032516', '2021102309'],\n    'date_str': ['19780312', '20120103'],\n    'speed': [123, 345]\n}) \n\ndf_date\n\n\n\n\nshape: (2, 3)\n\n\n\ndate_h_str\ndate_str\nspeed\n\n\nstr\nstr\ni64\n\n\n\n\n\"1987032516\"\n\"19780312\"\n123\n\n\n\"2021102309\"\n\"20120103\"\n345\n\n\n\n\n\n\n\n\n\nCode\ndf_date = df_date.with_columns(\n    pl.col('date_str')\n      .str.strptime(pl.Date, format='%Y%m%d')\n      .alias('date')\n)\n\n# df_date = df_date.with_columns(\n#     pl.col('date_h_str')\n#       .str.strptime(pl.Datetime, format='%Y%m%d%h%m%s')\n#       .alias('date_hour')\n# )\n\ndf_date\n\n\n\n\nshape: (2, 4)\n\n\n\ndate_h_str\ndate_str\nspeed\ndate\n\n\nstr\nstr\ni64\ndate\n\n\n\n\n\"1987032516\"\n\"19780312\"\n123\n1978-03-12\n\n\n\"2021102309\"\n\"20120103\"\n345\n2012-01-03\n\n\n\n\n\n\n\n\n\ncreate test df â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\ndf_test = pl.DataFrame(\n    {\n        'd_lat': [35.0,   43.0,   53.0,   214.0,  215.0,  209.0],\n        'd_lon': [1596.0, 1591.0, 1587.0, 1095.0, 1098.0, 1097.0],\n        'd_idx': [2301,   2301,   2301,   2316,   2316,   2316]\n    }\n)\nprint(df_test)\ndf_test = df_test.with_columns(\n    pl.col(\"d_lat\").mul(0.1), \n    pl.col(\"d_lon\").mul(0.1)\n)\nprint(df_test)",
    "crumbs": [
      "Home",
      "Test",
      "test code"
    ]
  }
]